{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Files\\\\DS&ML\\\\FraudGuard\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Files\\\\DS&ML\\\\FraudGuard'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    unzip_file: Path\n",
    "    status_file: Path\n",
    "    all_schema: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FraudGuard.constants import *\n",
    "from FraudGuard.utils.helpers import *\n",
    "from FraudGuard.utils.exception import CustomException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath=CONFIG_PATH, \n",
    "        params_filepath=PARAMS_PATH, \n",
    "        schema_filepath=SCHEMA_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "        schema = self.schema.COLUMNS\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        data_validation_config = DataValidationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            status_file=config.status_file,\n",
    "            unzip_file=config.unzip_file,\n",
    "            all_schema=schema,\n",
    "        )\n",
    "        return data_validation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from project import logger\n",
    "\n",
    "class DataValidation:\n",
    "    def __init__(self, config: DataValidationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def validate_data_types(self, data: pd.DataFrame, schema: dict) -> bool:\n",
    "        \"\"\"Validates the data types of columns against the schema.\"\"\"\n",
    "        type_mapping = {\n",
    "            'int': ['int64', 'int32'],\n",
    "            'float': ['float64', 'float32'],\n",
    "            'object': ['object'],\n",
    "            'str': ['object'], \n",
    "        }\n",
    "\n",
    "        for col, expected_type in schema.items():\n",
    "            if col not in data.columns:\n",
    "                continue \n",
    "                \n",
    "            actual_dtype = str(data[col].dtype)\n",
    "            allowed_dtypes = type_mapping.get(expected_type, [expected_type])\n",
    "\n",
    "            if actual_dtype not in allowed_dtypes:\n",
    "                logger.error(f\"Column '{col}': Expected type '{expected_type}', got '{actual_dtype}'\")\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def validate_column_presence(self, data: pd.DataFrame, schema: dict) -> bool:\n",
    "        \"\"\"Validates that all required columns are present in the data.\"\"\"\n",
    "        all_cols = list(data.columns)\n",
    "        expected_cols = set(schema.keys())\n",
    "        missing_cols = expected_cols - set(all_cols)\n",
    "\n",
    "        if missing_cols:\n",
    "            logger.error(f\"Missing columns: {missing_cols}\")\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "\n",
    "    def validation(self) -> bool:\n",
    "            data = pd.read_csv(self.config.unzip_file, low_memory=False)\n",
    "            schema = self.config.all_schema\n",
    "\n",
    "            logger.info(f\"Starting validation for data with shape: {data.shape}\")\n",
    "            \n",
    "            validation_results = {}\n",
    "            \n",
    "            # Run all validation checks\n",
    "            validation_results['column_presence'] = self.validate_column_presence(data, schema)\n",
    "            validation_results['data_types'] = self.validate_data_types(data, schema)\n",
    "            \n",
    "            # Overall validation status\n",
    "            is_valid = all(validation_results.values())\n",
    "            \n",
    "            # Log validation results\n",
    "            for check, result in validation_results.items():\n",
    "                logger.info(f\"{check}: {'PASSED' if result else 'FAILED'}\")\n",
    "            \n",
    "            logger.info(f\"Overall validation status: {'PASSED' if is_valid else 'FAILED'}\")\n",
    "            \n",
    "            # Write status to file\n",
    "            with open(self.config.status_file, 'w') as f:\n",
    "                f.write(f\"Validation_status: {is_valid}\")\n",
    "                \n",
    "            return is_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-26 16:22:21,769: INFO: helpers: yaml file: config_file\\config.yaml loaded successfully]\n",
      "[2025-05-26 16:22:21,773: INFO: helpers: yaml file: config_file\\params.yaml loaded successfully]\n",
      "[2025-05-26 16:22:21,780: INFO: helpers: yaml file: config_file\\schema.yaml loaded successfully]\n",
      "[2025-05-26 16:22:21,782: INFO: helpers: created directory at: artifacts]\n",
      "[2025-05-26 16:22:21,784: INFO: helpers: created directory at: artifacts/data_validation]\n",
      "[2025-05-26 16:22:21,875: INFO: 3317476208: Starting validation for data with shape: (51000, 12)]\n",
      "[2025-05-26 16:22:21,875: INFO: 3317476208: column_presence: PASSED]\n",
      "[2025-05-26 16:22:21,875: INFO: 3317476208: data_types: PASSED]\n",
      "[2025-05-26 16:22:21,875: INFO: 3317476208: Overall validation status: PASSED]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_validation_config = config.get_data_validation_config()\n",
    "    data_validation = DataValidation(data_validation_config)\n",
    "    data_validation.validation()\n",
    "except Exception as e:\n",
    "    raise CustomException(str(e), sys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
